{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b71fa08",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpylab\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import io\n",
    "import os\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56981cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Set up for GPU and load TF\n",
    "###\n",
    "\n",
    "print('GPU setup...')\n",
    "gpu_list = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "use_gpu    = False\n",
    "gpu_to_use = 0       # ignored if use_gpu is False\n",
    "gb_to_use  = 10      # ignored if use_gpu is False\n",
    "\n",
    "\n",
    "if use_gpu:\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(gpu_list[gpu_to_use],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=gb_to_use*1024)])\n",
    "        my_device = tf.config.get_logical_device_configuration(gpu_list[gpu_to_use])\n",
    "        tf.config.set_visible_devices(gpu_list[gpu_to_use], 'GPU')\n",
    "        logical_devices = tf.config.list_logical_devices('GPU')\n",
    "        assert len(logical_devices) == 1\n",
    "        print('Using only GPU', gpu_to_use, 'with configuration', my_device)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    except:\n",
    "        print('Unsuccessful GPU setup. If you do not have a GPU, ignore this message.')\n",
    "else:    \n",
    "    try:\n",
    "        # Disable all GPUS\n",
    "        tf.config.set_visible_devices([], 'GPU')\n",
    "        visible_devices = tf.config.get_visible_devices()\n",
    "        for device in visible_devices:\n",
    "            assert device.device_type != 'GPU'\n",
    "    except:\n",
    "        # Invalid device or cannot modify virtual devices once initialized.\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Input, Add, Concatenate, Dropout, AlphaDropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import mean_squared_error\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, TensorBoard, TerminateOnNaN, CSVLogger, ReduceLROnPlateau\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_shape: shape of a single data entry\n",
    "\n",
    "def build_model(in_shape, out_features=1, n_units=128):\n",
    "    layer_in = Input(shape=inshape)\n",
    "    layer_in = Dropout(0.2)(layer_in)\n",
    "    \n",
    "    hidden_layer_0 = Dense(n_units,   activation='relu', use_bias=True)(layer_in)\n",
    "    hidden_layer_1 = Dense(n_units/2, activation='relu', use_bias=True)(hidden_layer_0)\n",
    "    hidden_layer_2 = Dense(n_units/4, activation='relu', use_bias=True)(hidden_layer_1)\n",
    "    \n",
    "    hidden_layer_all = Concatenate()([layer_in, hidden_layer_0, hidden_layer_1, hidden_layer_2])\n",
    "    hidden_layer_all = Dense(n_units, activation='relu', use_bias=True)(hidden_layer_all)\n",
    "    \n",
    "    layer_out = Dropout(0.2)(hidden_layer_all)\n",
    "    layer_out = Dense(out_features, activation='none', use_bias=True)(layer_out)\n",
    "    \n",
    "    model = Model(inputs = layer_in, outputs = layer_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters and hyperparameters\n",
    "\n",
    "LR         = 0.01\n",
    "batch_size = 256\n",
    "epochs     = 200\n",
    "seed       = 1234\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "logdir_base = './logs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d8bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load in your data here\n",
    "data = 'CNT_13_12_1.696.csv'\n",
    "\n",
    "# split data into training/testing/validation, if needed\n",
    "mask = np.random.rand(len(data)) =< 0.8\n",
    "\n",
    "x_train = \n",
    "y_train = \n",
    "x_test = \n",
    "y_test = \n",
    "\n",
    "# shape of data for input, not including the batch size\n",
    "input_shape = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e54892",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Create directories\n",
    "###\n",
    "\n",
    "logdir = logdir_base # alter to keep track of your parameters and hyperparameters\n",
    "os.system ('mkdir -p '+logdir)\n",
    "print('Output to:', logdir)\n",
    "\n",
    "savedir = logdir\n",
    "os.system ('mkdir -p '+savedir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6be133",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Build model and train\n",
    "###\n",
    "\n",
    "print('\\nBuilding model...')\n",
    "\n",
    "opt  = tf.keras.optimizers.Adam(LR)\n",
    "loss = 'mse'\n",
    "met  = 'mean_absolute_error'\n",
    "cbk  = [ EarlyStopping(monitor='loss', patience=5),\n",
    "         ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3, min_delta=0.0, cooldown=0, min_lr=LR*(0.5**4)),\n",
    "         TerminateOnNaN(),\n",
    "         ModelCheckpoint(savedir+'/model.ckpt')\n",
    "       ]\n",
    "\n",
    "model = build_model(input_shape)\n",
    "model.compile(optimizer=opt, loss=loss, metrics=met)\n",
    "\n",
    "print('\\nStarting training loop...')\n",
    "history = model.fit(x_train, y_train,\n",
    "            batch_size = batch_size,\n",
    "            epochs     = epochs,\n",
    "            verbose    = 1,\n",
    "            callbacks  = cbk,\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
